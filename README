INCLUDEPATH += /usr/local/include \
               /usr/local/include/opencv4 \
               /usr/local/include/opencv4/opencv2

LIBS += /usr/local/lib/libopencv_highgui.so \
        /usr/local/lib/libopencv_core.so    \
        /usr/local/lib/libopencv_imgproc.so \
        /usr/local/lib/libopencv_imgcodecs.so \
        /usr/local/lib/*.so

opencv_001:
	掩膜操作（提高对比度）
		手动掩膜
		使用fliter2D进行掩膜操作
	总结：filter2D效率更高。
opencv_002:
	Mat相关操作：
		拷贝，复制，Scalar，指针操作，色域转换，定义小矩阵
opencv_003:
	对像素点进行操作
opencv_004:
	addWeighted图像融合
opencv_005:
	对每个像素点进行修改，提高图像的亮度，或降低图像的亮度。
opencv_006:
	基本几何形状绘制，文字显示
opencv_007:
	blur均值模糊（滤波）：取所有像素的平均值赋值给当前像素
	GaussianBlur高斯模糊（滤波）：均值滤波的kernel值为
			[1,1,1]
			[1,1,1]
			[1,1,1]
			        高斯滤波的kernel值为
			x = -2 w = 0.05
			x = -1 w = 0.15
			x = 0  w = 0.6
			x = 1  w = 0.15
			x = 2  w = 0.05
opencv_008:
	medianBlur中值滤波：对椒盐噪声有很好的抑制作用
			对kernel覆盖的像素进行排序，把中间值赋值给中间像素，就会去除小的干扰
	bilateralFilter双边滤波 ：保留图像梯度（轮廓），当有边界时中心的像素值很大，周围的像素值很小，可能会覆盖掉像素的边界特征。双边滤波可以设置阈值，当超过阈值后，就保留当前的像素值，否则就进行高斯滤波。 
opencv_009:
	Mat kernel = getStructuringElement(int shape,Size ksize,Point anchor);
	腐蚀：数值小的像素取代数值大的像素（暗的像素变多）
	膨胀：数值大的像素取代数值小的像素（亮的像素变多）
opencv_010:
	形态学操作：
		膨胀，腐蚀
		形态学梯度（膨胀-腐蚀）
		开操作（先腐蚀后膨胀：去除小亮点）：先腐蚀去除小的亮点，大的要保留的亮色图像也会被深色覆盖部分，膨胀操作会使面积变小的亮色恢复原有大小。
		闭操作（先膨胀后腐蚀：去除小黑点）、
		顶帽（开操作-原图像）
		黑帽（闭操作-原图像）
opencv_011:
	形态学操作，提取水平与垂直线
	1、读取图像
	2、转为灰度图像
	3、转为二值图像（将要提取的线设置为前景色白色，背景为黑色）
	4、创建水平提取算子kernel_h，创建垂直提取算子kernel_v
	5、先腐蚀，后膨胀，或直接使用morphologyEx进行开操作。
opencv_012:
	上采样和降采样
	高斯不同（DOG）：对一个图像进行一次高斯滤波，得到g1，再对g1进行高斯滤波得到	g2，g1-g2结果就是DOG。subtract(g1,g2,output_image,Mat());
opencv_013:
	基本阈值操作
	阈值类型：
		5种阈值处理方法
		1、THRESH_BINARY阈值二值化
		2、THRESH_BINARY_INY阈值反二值化
		3、THRESH_TRUNC截断（超过阈值的设为阈值，没超过的保持不变）
		4、THRESH_TOZERO阈值取零（超过阈值的保持不变，没超过阈值的取0）
		5、THRESH_TOZERO_INV（超过阈值的取0，没超过阈值的保持不变）	
		2种阈值寻找方法
		THRESH_OTSU 自动寻找合适的阈值，设置的阈值不再起作用（不用手动设置阈值）
		用法：用|或运算符与5种方法中的一种配合使用
		THRESH_TRIANGLE反二值化阈值
opencv_014:
	自定义线性滤波：
		kernel中心位置就是锚点
		卷积如何工作：把kernel放到像素数组上，求锚点周围覆盖的像素乘积之和（包括锚点），用来替换锚点覆盖下的像素的值，称为卷积处理。    
		                                                                                       
		常见算子：
		Robert算子：
		[+1,  0
		    0,-1]
		[  0,+1
		  -1,  0]
		Sonel算子：
		[-1,0,1
		 -2,0,2
		 -1,0,1]
		[-1,-2,-1
		   0, 0, 0
		   1, 2, 1]
		拉普拉斯算子：
		[ 0,-1, 0
		 -1, 4,-1
		   0,-1,0]
		Sobel算子和拉普拉斯算子用来寻找图像的梯度和边缘。
opencv_015:
	处理边缘：
		BORDER_CONSTANT：填充边缘用指定像素值
		BORDER_REPLICATE：填充边缘像素用已知的边缘值
		BORDER_WRAP：用另外一边的像素值来补偿填充
	给图像添加边缘：
		copyMakeBorder(Mat src,Mat dst,int top,int bottom,int left,int right,int borderTpe,Scalar value)
		卷积操作的函数可以指定边缘填充的类型：
			GaussianBlur(src,dst,Size(3,3),0,0,BORDER_WRAP);
opencv_016:
	卷积应用：图像边缘提取，计算图像像素的分布，求一阶导数，导数最大的地方就是边缘。
	图像边缘提取：
		边缘是什么——是像素值发生跃迁的地方，是图像的显著特征之一，在图像特征提取、对象检测、模式识别等方面都有重要的作用。
		如何捕捉/提取边缘——对图像求一阶导数delta=f(x)-f(x-1)，delta越大，说明像素在X方向上变化越大，边缘信号越强。
	Sobel算子提取边缘：
		水平梯度：Gx = kernel_x*I
		垂直梯度：Gy = kernel_y*I
		最终梯度：
				G = Square(Gx2+Gy2) ===>L1
				G = |Gx| + |Gy|            ===>L2  近似求解，速度快
		Sobel(
			inputArray Src,
			outputArray dst,
			int depth,		// 图像深度，-1会自动设置
			int dx,			// x方向求导的阶数
			int dy,			// y方向求导的阶数
			int ksize,		// kernel的大小，必须是奇数。
			double scale = 1,	
			double delta = 0,
			int borderType = BORDE_DEFAULT
		)
	Laplance算子二阶求导获取图像边缘：
		一阶导数的极大值点是边界，在二阶导数中过0点。
		1、高斯模糊去噪声
		2、转换为灰度图像
		3、拉普拉斯二阶导数计算
		4、取绝对值
		5、显示结果
opencv_017:

	Canny边缘检测：
		算法介绍：共五步
			1、高斯模糊 GaussianBlur
			2、灰度转换 cvtColor
			3、计算梯度 Sobel/Scharr
			4、非最大信号抑制：根据比较方向比较当前像素与左右或上下元素的值，如果该值是最大值则保留，不是最大值则置0；
			5、高低阈值输出二值图像：T1，T2为阈值，凡是高于T1的都保留，凡是小于T2的都丢弃。从高于T1的像素出发，凡是大于T2而且相互连接的，都保留。最终输出二值图像。推荐高低阈值比为T1：T2 = 3:1 / 2:1,其中T1为高阈值，T2为低阈值。
		Canny(
			inputArray src,		// 输入8-bit图像（0-255）也就是灰度图像
			outputArray dst,		//输出边缘图像，一般为二值图像，背景是黑色
			double threshold1,		//低阈值
			double threshold2,		//高阈值（低阈值大2倍或3倍）
			int aptertureSize,		//Sobel算子的Size，通常是3*3，取值3
			bool L2gradient		// 选择true表示是L2来归一化，否则使用L1归一化
		)
opencv_018:
	霍夫变换——直线检测：
		对于所有给出的点，投影到极坐标上，r = xcosɵ+ysinɵ，根据不同的角度，可以得到一条曲线。每个点都能得到一条曲线，如果多个点投影的曲线交于一点，说明这些点在同一条直线上，根据ɵ，r可以推算出直线的位置。
	对于任意一条直线上的点来说，变换到极坐标中，从[0,360]空间，可以得到r的大小。属于同一条直线上的点在极坐标(r,ɵ)必然在一点上有最强的信号出现，根据此反算到平面坐标中就可以得到直线上各点的像素坐标。从而得到直线。
	如果把图像转换成二值图像，前景色为白色，投影到极坐标上，最白的点就是最强信号，在同一直线上的点的累加。
	HoughLines(
		inputArray src,
		outputArray lines,
		double rho,		//生层极坐标时，像素扫描的步长
		double theta,		//生成极坐标时，角度步长，一般取CV_PI/180.0
		int threshold,		//阈值，当点数超过该值时才被看做是直线
		…...
	) 输出（r,ɵ）
	HoughLinesP()输出直线（x0,y0,x1,y1）

	霍夫变换——圆检测：
		对一个像素点，根据r和 ɵ，逐步增加，多个相同大小的圆交于一点，说明这些像素在同于个圆上，交点就是圆的圆心
		HoughCircles(
			inputArray image,	// 8位灰度图像
			outputArray circles,	//输出发现结果
			int method,		// 方法-HOUGH_GRADIENT
			double dp,		// 1
			double mindist,	//10 最短距离-可以分辨是两个圆，否则认为是同心圆
			double param1,	//
			double param2,	//中心点累加阈值
			int minradius,		//最小半径
			int maxradius		//最大半径
		)
opencv_019:	
	remap：像素重映射
map_x.create(src.size(),CV_32FC1);
map_y.create(src.size(),CV_32FC1);
remap(src,dst,map_x,map_y,INTER_LINEAR,BORDER_CONSTANT,Scalar(0,255,0));
// remap的映射表
void update_map(){
    for(int row=0;row<src.rows;row++){
        for(int col=0;col<src.cols;col++){
            switch (num) {
            case 0:// 图像缩小为原来的二分之一，相当于降采样
                if(col>=src.cols*0.25&&col<=src.cols*0.75&&row>=src.rows*0.25&&row<=src.rows*0.75){// 在显示窗口的中心显示缩小后的图片，没有没有被图像覆盖的地方用0覆盖
                    // 保留偶数行和偶数列的像素
			  // 映射表里的元素是该位置应该对应原图像中像素的位置
                    map_x.at<float>(row,col) = 2*(col-src.cols*0.25);
                    map_y.at<float>(row,col) = 2*(row-src.rows*0.25);
                }else {
                    map_x.at<float>(row,col) = 0;
                    map_y.at<float>(row,col) = 0;
                }
                break;
            case 1:// 图像关于y轴翻转
                map_x.at<float>(row,col) = src.cols-col;
                map_y.at<float>(row,col) = row;
                break;
            case 2:// 图像关于x轴翻转
                map_x.at<float>(row,col) = col;
                map_y.at<float>(row,col) = src.rows-row;
                break;
            case 3:// 图像关于xy轴翻转
                map_x.at<float>(row,col) = src.cols-col;
                map_y.at<float>(row,col) = src.rows-row;
                break;
            }
        }
    }
}
opencv_020:
	直方图：对图像中的像素值进行统计，显示成直方图。
		直方图反应了图像灰度分布情况，是图像的统计学特征。
	直方图均衡化：是一种提高图像对比度的方法
			使用remap将图像灰度从一个分布映射到另一个分布。
			equalizeHist(src,dst);//输入为8位的单通道图像。
opencv_021:
	直方图计算：
		dims表示维度，对灰度图像来说只有一个通道，dims=1
		bins 表示在维度中子区域大小划分，bins=256，划分为256个级别
		range表示值的阈值，灰度值范围为[0,255]之间
	
	把多通道图像分为多个单通道图像,都是灰度图像，但灰度的值对应的是每个通道原有值的大小	
	split(
		const Mat& src,	// 输入图像
		Mat * mvbegin	// 输出图像数组
	)
	calcHist(
		const Mat* images,	// 输入图像指针
		int images,		//图像数目
		const int *channels, 	// 通道数
		inputArray mask,	// 输入mask，可选
		outputArray hist,	// 输出直方图数据
		int dims,		// 维数
		const int * histsize,	// 直方图级数
		const float* range,	// 值域范围
		bool uniform,		// true by default
		bool accumulate	// false by default
	)
	cvRound(float/double/int);//将浮点数四舍五入到最接近的整数
	
	normalize：
	
void cv::normalize 
(
InputArray src, 
InputOutputArray dst, 
double alpha = 1, 
double beta = 0, 
int norm_type = NORM_L2, 
int dtype = -1, 
InputArray mask = noArray() 
)


Python:dst=cv.normalize(src, dst[, alpha[, beta[, norm_type[, dtype[, mask]]]]])

#include <opencv2/core.hpp>
Normalizes the norm or value range of an array. 
The function cv::normalize normalizes scale and shift the input array elements so that 
∥dst∥Lp=alpha
(where p=Inf, 1 or 2) when normType=NORM_INF, NORM_L1, or NORM_L2, respectively; or so that 
minIdst(I)=alpha,maxIdst(I)=beta
when normType=NORM_MINMAX (for dense arrays only). The optional mask specifies a sub-array to be normalized. This means that the norm or min-n-max are calculated over the sub-array, and then this sub-array is modified to be normalized. If you want to only use the mask to calculate the norm or min-max but modify the whole array, you can use norm and Mat::convertTo.
In case of sparse matrices, only the non-zero values are analyzed and transformed. Because of this, the range transformation for sparse matrices is not allowed since it can shift the zero level.
Possible usage with some positive example data: 
vector<double> positiveData = { 2.0, 8.0, 10.0 };
vector<double> normalizedData_l1, normalizedData_l2, normalizedData_inf, normalizedData_minmax;
// Norm to probability (total count)
// sum(numbers) = 20.0
// 2.0 0.1 (2.0/20.0)
// 8.0 0.4 (8.0/20.0)
// 10.0 0.5 (10.0/20.0)
normalize(positiveData, normalizedData_l1, 1.0, 0.0, NORM_L1);
// Norm to unit vector: ||positiveData|| = 1.0
// 2.0 0.15
// 8.0 0.62
// 10.0 0.77
normalize(positiveData, normalizedData_l2, 1.0, 0.0, NORM_L2);
// Norm to max element
// 2.0 0.2 (2.0/10.0)
// 8.0 0.8 (8.0/10.0)
// 10.0 1.0 (10.0/10.0)
normalize(positiveData, normalizedData_inf, 1.0, 0.0, NORM_INF);
// Norm to range [0.0;1.0]
// 2.0 0.0 (shift to left border)
// 8.0 0.75 (6.0/8.0)
// 10.0 1.0 (shift to right border)
normalize(positiveData, normalizedData_minmax, 1.0, 0.0, NORM_MINMAX);
Parameters
src input array. 
dst output array of the same size as src . 
alpha norm value to normalize to or the lower range boundary in case of the range normalization.在范围归一化的情况下，要归一化到下限边界的标准值。 
beta upper range boundary in case of the range normalization; it is not used for the norm normalization. 范围归一化的情况下的范围上限; 它不用于规范归一化。
norm_type normalization type (see cv::NormTypes). 
dtype when negative, the output array has the same type as src; otherwise, it has the same number of channels as src and the depth =CV_MAT_DEPTH(dtype). 
mask optional operation mask. 
opencv_022:
	直方图比较：
		相关性比较（Correlation）
		Chi-Square（卡方比较）
		Intersection（十字交叉性）
		Bhattacharyya distance（巴氏距离）
	步骤：
      		a.先用cvtColor()把图像从RGB色彩空间转换到HSV色彩空间;
        		b.计算图像的直方图，然后归一化到[0~1]之间，用到函数 calcHist() 和 normalize() ；
        		c.使用上述的四种方法之一进行比较，用到函数compareHist()。
opencv_023:
	反射投影：
        原理：
            函数cv :: calcBackProject计算直方图的反向投影。
            也就是说，类似于calcHist，该函数在每个位置（x，y）收集输入图像中所选通道的值，并找到相应的直方图bin。
            但是该函数不是增加它，而是读取bin值，按比例缩放它，并将其存储在backProject（x，y）中。
            在统计方面，该函数根据直方图表示的经验概率分布计算每个元素值的概率。
            例如，查看如何在场景中查找和跟踪明亮的对象：跟踪之前，将对象显示给相机，使其几乎覆盖整个画面。
            计算色调直方图。直方图可能具有很强的最大值，对应于对象中的主要颜色。
            跟踪时，请使用该预先计算的直方图计算每个输入视频帧的色相平面的反投影。
            限制背投阈值以抑制较弱的色彩。抑制颜色饱和度不足且像素太暗或太亮的像素也可能是有意义的。
            在结果图片中找到连接的组件，然后选择最大的组件。
        步骤：
            1、是图像转换到HSV色域空间
            2、取出HSV空间的H通道进行calcHist,对直方图结果进行normalize
            3、对归一化后的结果进型calcBackProject，得到反向投影图像。
opencv_024:
	模板匹配（template match）：
		模板匹配就是在整个图像区域发现与给定图像匹配的小块区域。
		所以模板匹配首先需要一个模板对象T（给定的子图像），另外需要一个待检测的图像-源图像S，工作方法就是在待检测的图像上，从左到右，从上到下计算模板与子图像的匹配度，匹配成都越大，两者形同的可能性越大。
	匹配算法：
		归一化平方不同（值越小越相关，0表示相同）
		归一化相关性（1相关0不相关）
		归一化相关系数（1相关0不相关）
	matchTemplate(
		inputArray image,	//源图像，必须是8位或32位浮点数图像
		inputArray templ,	//模板图像，类型与输入图像一致
		outoutArray result,	//输出结果，必须是单通道32位浮点数，假设源图像大小为W*H，模板图像大小w*h，则结果必须为W-w+1,H-h+1的大小
		int method,		// 使用的匹配方法
		inputArray mask=noArray()
	)
opencv_025:
	轮廓发现：
		轮廓发现是基于图像边缘提取的基础寻找对象轮廓的方法。所以边缘提取的阈值选定会影响最终轮廓发现结果。
	发现轮廓	
	findContours(
		inputArray binImage,		// 输入图像
		outputArray contours,		//全部轮廓
		outputArray hierachy,		//
		int mode,			// 轮廓返回的模式
		int method,			//发现方法
		Point offset=Point()		//轮廓像素的位移，默认为（0,0），没有位移
	)
第三个参数：hierarchy，定义为“vector<Vec4i> hierarchy”，先来看一下Vec4i的定义：
	typedef  Vec<int, 4>   Vec4i;
	Vec4i是Vec<int,4>的别名，定义了一个“向量内每一个元素包含了4个int型变量”的向量。
	所以从定义上看，hierarchy也是一个向量，向量内每个元素保存了一个包含4个int整型的数组。
	向量hiararchy内的元素和轮廓向量contours内的元素是一一对应的，向量的容量相同。
	hierarchy向量内每一个元素的4个int型变量——hierarchy[i][0]~hierarchy[i][3]，分别表示第 i个轮廓的后一个轮廓、前一个轮廓、父轮廓、内嵌轮廓的索引编号。如果当前轮廓没有对应的后一个 轮廓、前一个轮廓、父轮廓或内嵌轮廓的话，则hierarchy[i][0] ~hierarchy[i][3]的相应位被设置为默认值-1。
第四个参数：int型的mode，定义轮廓的检索模式：
	取值一：CV_RETR_EXTERNAL只检测最外围轮廓，包含在外围轮廓内的内围轮廓被忽略
	取值二：CV_RETR_LIST   检测所有的轮廓，包括内围、外围轮廓，但是检测到的轮廓不建立		等级关系，彼此之间独立，没有等级关系，这就意味着这个检索模式下不存在父轮廓或内		嵌轮廓，所以hierarchy向量内所有元素的第3、第4个分量都会被置为-1，具体下文会		讲到
	取值三：CV_RETR_CCOMP  检测所有的轮廓，但所有轮廓只建立两个等级关系，外围为顶层，		若外围内的内围轮廓还包含了其他的轮廓信息，则内围内的所有轮廓均归属于顶层
	取值四：CV_RETR_TREE， 检测所有轮廓，所有轮廓建立一个等级树结构。外层轮廓包含内		层轮廓，内层轮廓还可以继续包含内嵌轮廓。
第五个参数：int型的method，定义轮廓的近似方法：
	取值一：CV_CHAIN_APPROX_NONE 保存物体边界上所有连续的轮廓点到contours向量内
	取值二：CV_CHAIN_APPROX_SIMPLE仅保存轮廓的拐点信息，把所有轮廓拐点处的点保		存入contours向量内，拐点与拐点之间直线段上的信息点不予保留
	取值三和四：CV_CHAIN_APPROX_TC89_L1，CV_CHAIN_APPROX_TC89_KCOS使		用teh-Chinl chain 近似算法
第六个参数：Point偏移量，所有的轮廓信息相对于原始图像对应点的偏移量，相当于在每一个检测出的		轮廓点上加上该偏移量，并且Point还可以是负值！

异同。
	绘制轮廓
	drawContours(
		inputoutputArray binimg,
		outputArray contours,	//全部发现的轮廓对象
		int contourIdx,//轮廓索引号
		const Scalar& color,//绘制时的颜色
		int tickness,//线的宽度
		int linetype,
		inputArray hierarchy，
		int maxlevel,//	最大层数
		Point offset=Point()//轮廓位移
	)	
	步骤：
		1、canny轮廓提取
		2、findContours()发现轮廓
		3、drawContours()绘制轮廓
opencv_026:
	凸包Convex Hull：
		在一个多边形边缘或内部任意两点的连线都包含在多边形边界或内部。
		包含点集合S中所有点的最小凸多边形称为凸包。
	如何找到凸包：
		Graham扫描算法：
			首先选择Y方向最低的点作为起始点p0，从p0开始极坐标扫描，依次添加p1...pn（排序顺序是根据极坐标的角度大小，逆时针方向），对每个点pi来说，如果添加pi到凸包导致一个左转向（逆时针方法）则添加该点到凸包，反之如果导致一个右转（顺时针方向）删除该点从凸包中。
		ConvexHull(
			inputArray points,//输入候选点，来自findContours
			outputArray hull,//凸包
			bool clockwise,//default true顺指针方向
			bool returnPoint//true 返回点的个数，如果第二个参数是vector<Point>则自动忽略
		)
	步骤：
		1、读取图像，转为灰度图像，可以对灰度图像做适当的处理
		2、Canny发现边缘
		3、findContours提取轮廓
		4、convexHull发现凸包
		5、使用drawContours绘制轮廓与边缘opencv
opencv_027:
	轮廓周围绘制矩形或圆形框：
		1、提取边缘（也可以直接把灰度图像使用threshold转为二值图像用于发现轮廓）
		2、发现轮廓
		3、根据轮廓得到多边形apptoxPloyDP，圆minEnclosingCircle，矩形boundingRect
		4、绘制多边形drawContours、绘制圆circle、绘制矩形retangle






Exception:
	

terminate called after throwing an instance of 'cv::Exception'
what():  OpenCV(4.2.0) /home/dogpi/Downloads/opencv-4.2.0/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'
原因：1、可能是加载的图片路径错误，检查路径和文件名是否正确，在imread中
	2、可能是要显示的Mat没有进行初始化就进行赋值并显示，如下代码在没有对drawImge初始化时就赋值并显示就会报错。
Mat drawImage = Mat::zeros(canny_mat.size(),CV_8UC3);
    for(size_t i = 0;i<contours.size();i++){
        Scalar color = Scalar(rng.uniform(0,255),rng.uniform(0,255),rng.uniform(0,255));
        drawContours(drawImage,contours,(int)i,color);
        drawContours(drawImage,contours,(int)i,color);
    }
    imshow("result",drawImage);

